{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00d0ZdMZNZRB"
      },
      "source": [
        "# Noisy 10-Qubit Adaptive QNN Experiment\n",
        "## Testing with Realistic NISQ Error Rates\n",
        "\n",
        "**Experiment Overview:**\n",
        "- Demonstrates adaptive QNN under realistic quantum noise\n",
        "- NISQ error rates: 1% single-qubit, 1.5% two-qubit, 2% measurement\n",
        "- 10 qubits, 30 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41zLHlKJNZRF"
      },
      "source": [
        "## pip Installation and Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kFS0iyoNZRG",
        "outputId": "2124ec31-ee4a-4202-c7a1-7b64911dd4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n",
            "Wed Oct 15 09:33:50 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   34C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "✓ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Check environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running on Google Colab\")\n",
        "\n",
        "    # GPU check\n",
        "    !nvidia-smi\n",
        "\n",
        "    # Install packages\n",
        "    !pip install -q pennylane pennylane-lightning-gpu\n",
        "    !pip install -q scikit-learn matplotlib seaborn\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")\n",
        "\n",
        "print(\"\\n✓ Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIO7EQ4YNZRI",
        "outputId": "6aa1f814-da88-4f74-ec24-d6a6c97888a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Imports complete\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.datasets import load_wine, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "print(\"✓ Imports complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inh4mTZdNZRJ"
      },
      "source": [
        "## Configuration with Realistic Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoCf0jTVNZRJ",
        "outputId": "9097241c-46c7-4843-8504-a6aae726d660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GPU acceleration available\n",
            "\n",
            "Configuration:\n",
            "  Qubits: 10\n",
            "  Noise Model: Realistic NISQ (IBM/Google hardware)\n",
            "    Single-qubit error: 1.0%\n",
            "    Two-qubit error: 1.5%\n",
            "    Measurement error: 2.0%\n",
            "  Epochs: 30\n",
            "  Strategy: ucb\n",
            "  Dataset: wine\n"
          ]
        }
      ],
      "source": [
        "class NoisyConfig:\n",
        "    \"\"\"Configuration with realistic NISQ noise parameters\"\"\"\n",
        "\n",
        "    # Quantum system\n",
        "    N_QUBITS = 10\n",
        "    N_LAYERS = 2\n",
        "\n",
        "    # Training\n",
        "    LEARNING_RATE = 0.01\n",
        "    N_EPOCHS = 30\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    # Realistic NISQ error rates (IBM Quantum / Google Sycamore)\n",
        "    NOISE_PARAMS = {\n",
        "        'single_qubit_error': 0.01,      # 1% per gate\n",
        "        'two_qubit_error': 0.015,        # 1.5% per gate\n",
        "        'measurement_error': 0.02,       # 2% per measurement\n",
        "        'description': 'Realistic NISQ (IBM/Google hardware)'\n",
        "    }\n",
        "\n",
        "    # Adaptive strategy\n",
        "    STRATEGY = 'ucb'\n",
        "    UCB_C = 2.0\n",
        "\n",
        "    # Dataset\n",
        "    DATASET = 'wine'\n",
        "    TEST_SIZE = 0.3\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Device - try GPU\n",
        "    try:\n",
        "        test_dev = qml.device('lightning.gpu', wires=2)\n",
        "        DEVICE_NAME = 'lightning.gpu'\n",
        "        print(\"✓ GPU acceleration available\")\n",
        "    except:\n",
        "        DEVICE_NAME = 'default.mixed'  # For noise simulation\n",
        "        print(\"Using CPU with mixed-state simulator\")\n",
        "\n",
        "    # Output\n",
        "    VERBOSE = True\n",
        "    PLOT_RESULTS = True\n",
        "    SAVE_RESULTS = True\n",
        "    OUTPUT_DIR = Path('results/noisy_10q')\n",
        "\n",
        "config = NoisyConfig()\n",
        "config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Qubits: {config.N_QUBITS}\")\n",
        "print(f\"  Noise Model: {config.NOISE_PARAMS['description']}\")\n",
        "print(f\"    Single-qubit error: {config.NOISE_PARAMS['single_qubit_error']*100}%\")\n",
        "print(f\"    Two-qubit error: {config.NOISE_PARAMS['two_qubit_error']*100}%\")\n",
        "print(f\"    Measurement error: {config.NOISE_PARAMS['measurement_error']*100}%\")\n",
        "print(f\"  Epochs: {config.N_EPOCHS}\")\n",
        "print(f\"  Strategy: {config.STRATEGY}\")\n",
        "print(f\"  Dataset: {config.DATASET}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XjOUEUANZRK"
      },
      "source": [
        "## Helper Classes (Data, Features, Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtZ8ipuiNZRL",
        "outputId": "4f400dbd-a236-402d-ca40-6d29f7cb2d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Helper classes defined\n"
          ]
        }
      ],
      "source": [
        "class DataLoader:\n",
        "    @staticmethod\n",
        "    def load_dataset(name='wine'):\n",
        "        datasets = {'iris': load_iris, 'wine': load_wine}\n",
        "        data = datasets[name]()\n",
        "        X, y = data.data, data.target\n",
        "        mask = y < 2\n",
        "        return X[mask], y[mask], data.feature_names\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(X_train, X_test, y_train, y_test):\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "class FeatureSelector:\n",
        "    @staticmethod\n",
        "    def pca(X_train, X_test, n_components):\n",
        "        pca = PCA(n_components=n_components)\n",
        "        return pca.fit_transform(X_train), pca.transform(X_test)\n",
        "\n",
        "    @staticmethod\n",
        "    def correlation(X_train, X_test, y_train, n_features):\n",
        "        correlations = np.array([np.corrcoef(X_train[:, i], y_train)[0, 1]\n",
        "                                for i in range(X_train.shape[1])])\n",
        "        top_indices = np.argsort(np.abs(correlations))[-n_features:]\n",
        "        return X_train[:, top_indices], X_test[:, top_indices]\n",
        "\n",
        "    @staticmethod\n",
        "    def mutual_info(X_train, X_test, y_train, n_features):\n",
        "        mi_scores = mutual_info_classif(X_train, y_train, random_state=42)\n",
        "        top_indices = np.argsort(mi_scores)[-n_features:]\n",
        "        return X_train[:, top_indices], X_test[:, top_indices]\n",
        "\n",
        "    @staticmethod\n",
        "    def random_selection(X_train, X_test, n_features):\n",
        "        np.random.seed(42)\n",
        "        indices = np.random.choice(X_train.shape[1], n_features, replace=False)\n",
        "        return X_train[:, indices], X_test[:, indices]\n",
        "\n",
        "class QuantumEncoder:\n",
        "    @staticmethod\n",
        "    def angle_encoding(features, wires):\n",
        "        for i, wire in enumerate(wires):\n",
        "            if i < len(features):\n",
        "                qml.RY(features[i], wires=wire)\n",
        "\n",
        "    @staticmethod\n",
        "    def amplitude_encoding(features, wires):\n",
        "        n_amplitudes = 2 ** len(wires)\n",
        "        padded = np.zeros(n_amplitudes)\n",
        "        padded[:len(features)] = features\n",
        "        normalized = padded / np.linalg.norm(padded) if np.linalg.norm(padded) > 0 else padded\n",
        "        qml.AmplitudeEmbedding(normalized, wires=wires, normalize=True)\n",
        "\n",
        "print(\"✓ Helper classes defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIvUtXTENZRL"
      },
      "source": [
        "## Noisy Quantum Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOObHlSNNZRM",
        "outputId": "7120fe5f-56e0-4b2c-9ca6-a5c93e6928f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ NoisyQuantumNeuralNetwork defined\n"
          ]
        }
      ],
      "source": [
        "from autograd import numpy as anp\n",
        "\n",
        "class NoisyQuantumNeuralNetwork:\n",
        "    \"\"\"QNN with realistic NISQ noise model\"\"\"\n",
        "\n",
        "    def __init__(self, n_qubits, n_layers, encoding_method='angle', noise_params=None):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_layers = n_layers\n",
        "        self.encoding_method = encoding_method\n",
        "        self.noise_params = noise_params or {\n",
        "            'single_qubit_error': 0,\n",
        "            'two_qubit_error': 0,\n",
        "            'measurement_error': 0\n",
        "        }\n",
        "\n",
        "        # Check if noise is actually being used (only check numeric noise parameters)\n",
        "        noise_keys = ['single_qubit_error', 'two_qubit_error', 'measurement_error']\n",
        "        has_noise = any(\n",
        "            self.noise_params.get(key, 0) > 0\n",
        "            for key in noise_keys\n",
        "        )\n",
        "\n",
        "        # Device selection - noise requires mixed state simulator\n",
        "        if has_noise:\n",
        "            # Noise simulation requires default.mixed (supports density matrices)\n",
        "            try:\n",
        "                self.dev = qml.device('default.mixed', wires=n_qubits)\n",
        "                print(f\"  Using default.mixed for {n_qubits} qubits with noise\")\n",
        "            except:\n",
        "                self.dev = qml.device('default.qubit', wires=n_qubits)\n",
        "                print(f\"  Using default.qubit for {n_qubits} qubits (no noise support)\")\n",
        "        else:\n",
        "            # No noise - can use fast GPU simulator\n",
        "            try:\n",
        "                if hasattr(config, 'USE_GPU') and config.USE_GPU:\n",
        "                    self.dev = qml.device('lightning.gpu', wires=n_qubits)\n",
        "                    print(f\"  Using GPU for {n_qubits} qubits (no noise)\")\n",
        "                else:\n",
        "                    self.dev = qml.device(config.DEVICE_NAME, wires=n_qubits)\n",
        "            except:\n",
        "                self.dev = qml.device('default.qubit', wires=n_qubits)\n",
        "                print(f\"  Using default.qubit for {n_qubits} qubits\")\n",
        "\n",
        "        # Parameters - ensure numpy array\n",
        "        self.n_params = n_layers * n_qubits * 3\n",
        "        self.params = np.random.randn(self.n_params) * 0.1\n",
        "\n",
        "        # Circuit metrics\n",
        "        self.gate_count = 0\n",
        "        self.circuit_depth = 0\n",
        "\n",
        "        # Create QNode WITH interface='autograd' - CRITICAL FIX\n",
        "        self.qnode = qml.QNode(self._circuit, self.dev, interface='autograd')\n",
        "\n",
        "    def _circuit(self, features, params):\n",
        "        \"\"\"Quantum circuit with noise\"\"\"\n",
        "        wires = range(self.n_qubits)\n",
        "\n",
        "        # Reset gate count for this circuit execution\n",
        "        self.gate_count = 0\n",
        "\n",
        "        # Encoding\n",
        "        if self.encoding_method == 'angle':\n",
        "            for i in range(min(len(features), self.n_qubits)):\n",
        "                qml.RY(features[i], wires=i)\n",
        "                self.gate_count += 1\n",
        "        elif self.encoding_method == 'amplitude':\n",
        "            n_amplitudes = 2 ** self.n_qubits\n",
        "            padded = np.zeros(n_amplitudes)\n",
        "            padded[:len(features)] = features\n",
        "            normalized = padded / np.linalg.norm(padded) if np.linalg.norm(padded) > 0 else padded\n",
        "            qml.AmplitudeEmbedding(normalized, wires=wires, normalize=True)\n",
        "            self.gate_count += 1\n",
        "\n",
        "        # Parameterized layers with noise\n",
        "        for layer in range(self.n_layers):\n",
        "            for i in range(self.n_qubits):\n",
        "                idx = layer * self.n_qubits * 3 + i * 3\n",
        "                qml.RX(params[idx], wires=i)\n",
        "                qml.RY(params[idx + 1], wires=i)\n",
        "                qml.RZ(params[idx + 2], wires=i)\n",
        "                self.gate_count += 3\n",
        "\n",
        "                # Apply noise after single-qubit gates\n",
        "                if self.noise_params.get('single_qubit_error', 0) > 0:\n",
        "                    qml.DepolarizingChannel(self.noise_params['single_qubit_error'], wires=i)\n",
        "\n",
        "            # Entangling layer\n",
        "            for i in range(self.n_qubits):\n",
        "                qml.CNOT(wires=[i, (i + 1) % self.n_qubits])\n",
        "                self.gate_count += 1\n",
        "\n",
        "                # Apply noise after two-qubit gates\n",
        "                if self.noise_params.get('two_qubit_error', 0) > 0:\n",
        "                    qml.DepolarizingChannel(self.noise_params['two_qubit_error'], wires=i)\n",
        "                    qml.DepolarizingChannel(self.noise_params['two_qubit_error'], wires=(i + 1) % self.n_qubits)\n",
        "\n",
        "        return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "    def predict_single(self, features):\n",
        "        \"\"\"Predict single sample\"\"\"\n",
        "        output = self.qnode(features, self.params)\n",
        "        return 1 if output > 0 else 0\n",
        "\n",
        "    def predict_batch(self, X):\n",
        "        \"\"\"Predict batch of samples\"\"\"\n",
        "        return np.array([self.predict_single(x) for x in X])\n",
        "\n",
        "    def train_step(self, X_batch, y_batch, learning_rate):\n",
        "        \"\"\"Single training step with gradient descent\"\"\"\n",
        "        def loss_fn(params):\n",
        "            # Use autograd numpy for operations inside gradient computation\n",
        "            predictions = anp.array([self.qnode(x, params) for x in X_batch])\n",
        "            targets = 2 * y_batch - 1\n",
        "            return anp.mean((predictions - targets) ** 2)\n",
        "\n",
        "        # Compute gradients - argnum=0 specifies first argument\n",
        "        grad_fn = qml.grad(loss_fn, argnum=0)\n",
        "        gradients = grad_fn(self.params)\n",
        "\n",
        "        # Update parameters (regular numpy is fine here)\n",
        "        self.params = self.params - learning_rate * np.array(gradients)\n",
        "\n",
        "        return float(loss_fn(self.params))\n",
        "\n",
        "print(\"✓ NoisyQuantumNeuralNetwork defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJljWhRrNZRM"
      },
      "source": [
        "## Adaptive Controller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT1RxlUqNZRN",
        "outputId": "43690464-ba3a-46bb-beee-a57eb3c3c52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ AdaptiveController defined\n"
          ]
        }
      ],
      "source": [
        "class AdaptiveController:\n",
        "    \"\"\"UCB-based adaptive configuration selection\"\"\"\n",
        "\n",
        "    def __init__(self, configurations, strategy='ucb'):\n",
        "        self.configurations = configurations\n",
        "        self.strategy = strategy\n",
        "        self.rewards = {cfg: [] for cfg in configurations}\n",
        "        self.selection_counts = {cfg: 0 for cfg in configurations}\n",
        "        self.total_selections = 0\n",
        "        self.selection_history = []\n",
        "        self.reward_history = []\n",
        "        self.ucb_c = config.UCB_C\n",
        "\n",
        "    def select_configuration(self):\n",
        "        # Ensure each tried once\n",
        "        if self.total_selections < len(self.configurations):\n",
        "            config_name = self.configurations[self.total_selections]\n",
        "            self.selection_history.append(config_name)\n",
        "            return config_name\n",
        "\n",
        "        # UCB selection\n",
        "        ucb_values = {}\n",
        "        for cfg in self.configurations:\n",
        "            if len(self.rewards[cfg]) == 0:\n",
        "                ucb_values[cfg] = float('inf')\n",
        "            else:\n",
        "                mean_reward = np.mean(self.rewards[cfg])\n",
        "                exploration = self.ucb_c * np.sqrt(\n",
        "                    np.log(self.total_selections) / self.selection_counts[cfg]\n",
        "                )\n",
        "                ucb_values[cfg] = mean_reward + exploration\n",
        "\n",
        "        selected = max(ucb_values, key=ucb_values.get)\n",
        "        self.selection_history.append(selected)\n",
        "        return selected\n",
        "\n",
        "    def update(self, configuration, reward):\n",
        "        self.rewards[configuration].append(reward)\n",
        "        self.selection_counts[configuration] += 1\n",
        "        self.total_selections += 1\n",
        "        self.reward_history.append(reward)\n",
        "\n",
        "    def get_best_configuration(self):\n",
        "        mean_rewards = {\n",
        "            cfg: np.mean(rewards) if rewards else 0\n",
        "            for cfg, rewards in self.rewards.items()\n",
        "        }\n",
        "        return max(mean_rewards, key=mean_rewards.get)\n",
        "\n",
        "    def get_statistics(self):\n",
        "        stats = []\n",
        "        for cfg in self.configurations:\n",
        "            if self.rewards[cfg]:\n",
        "                stats.append({\n",
        "                    'configuration': cfg,\n",
        "                    'mean_reward': np.mean(self.rewards[cfg]),\n",
        "                    'std_reward': np.std(self.rewards[cfg]),\n",
        "                    'count': len(self.rewards[cfg])\n",
        "                })\n",
        "        return sorted(stats, key=lambda x: x['mean_reward'], reverse=True)\n",
        "\n",
        "print(\"✓ AdaptiveController defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Citk3ylaNZRN"
      },
      "source": [
        "## Main Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmzbhUq6NZRO",
        "outputId": "29dd4a23-fa3d-4b1a-898a-cfc6bf6db8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ NoisyAdaptiveQNNTrainer defined\n"
          ]
        }
      ],
      "source": [
        "class NoisyAdaptiveQNNTrainer:\n",
        "    \"\"\"Main training pipeline with noise\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Load data\n",
        "        print(\"Loading dataset...\")\n",
        "        X, y, _ = DataLoader.load_dataset(config.DATASET)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=config.TEST_SIZE, random_state=config.RANDOM_STATE\n",
        "        )\n",
        "        X_train, X_test, y_train, y_test = DataLoader.preprocess(\n",
        "            X_train, X_test, y_train, y_test\n",
        "        )\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "\n",
        "        print(f\"Dataset: {config.DATASET}\")\n",
        "        print(f\"Training: {len(X_train)}, Test: {len(X_test)}\")\n",
        "\n",
        "        # Configurations\n",
        "        feature_methods = ['PCA', 'Correlation', 'MutualInfo', 'Random']\n",
        "        encoding_methods = ['angle', 'amplitude']\n",
        "        self.configurations = [\n",
        "            f\"{fm}+{em}\" for fm in feature_methods for em in encoding_methods\n",
        "        ]\n",
        "\n",
        "        # Controller\n",
        "        self.controller = AdaptiveController(self.configurations, config.STRATEGY)\n",
        "\n",
        "        # Tracking\n",
        "        self.training_history = {\n",
        "            'train_acc': [],\n",
        "            'val_acc': [],\n",
        "            'config': [],\n",
        "            'epoch_time': [],\n",
        "            'gate_count': [],\n",
        "            'circuit_depth': []\n",
        "        }\n",
        "\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def apply_feature_selection(self, method):\n",
        "        if method == 'PCA':\n",
        "            return FeatureSelector.pca(self.X_train, self.X_test, config.N_QUBITS)\n",
        "        elif method == 'Correlation':\n",
        "            return FeatureSelector.correlation(self.X_train, self.X_test, self.y_train, config.N_QUBITS)\n",
        "        elif method == 'MutualInfo':\n",
        "            return FeatureSelector.mutual_info(self.X_train, self.X_test, self.y_train, config.N_QUBITS)\n",
        "        elif method == 'Random':\n",
        "            return FeatureSelector.random_selection(self.X_train, self.X_test, config.N_QUBITS)\n",
        "\n",
        "    def train_epoch(self, qnn, X_train, X_test, y_train, y_test):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Training\n",
        "        n_samples = len(X_train)\n",
        "        indices = np.random.permutation(n_samples)\n",
        "\n",
        "        for i in range(0, n_samples, config.BATCH_SIZE):\n",
        "            batch_indices = indices[i:i + config.BATCH_SIZE]\n",
        "            qnn.train_step(X_train[batch_indices], y_train[batch_indices], config.LEARNING_RATE)\n",
        "\n",
        "        # Evaluation\n",
        "        train_pred = qnn.predict_batch(X_train)\n",
        "        train_acc = np.mean(train_pred == y_train)\n",
        "\n",
        "        val_pred = qnn.predict_batch(X_test)\n",
        "        val_acc = np.mean(val_pred == y_test)\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        return train_acc, val_acc, epoch_time, qnn.gate_count, qnn.circuit_depth\n",
        "\n",
        "    def run(self):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"STARTING NOISY ADAPTIVE QNN TRAINING\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Noise: {config.NOISE_PARAMS['description']}\")\n",
        "        print(f\"Epochs: {config.N_EPOCHS}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        for epoch in range(config.N_EPOCHS):\n",
        "            # Select configuration\n",
        "            config_name = self.controller.select_configuration()\n",
        "            feature_method, encoding_method = config_name.split('+')\n",
        "\n",
        "            # Feature selection\n",
        "            X_train_reduced, X_test_reduced = self.apply_feature_selection(feature_method)\n",
        "\n",
        "            # Create noisy QNN\n",
        "            qnn = NoisyQuantumNeuralNetwork(\n",
        "                config.N_QUBITS, config.N_LAYERS, encoding_method, config.NOISE_PARAMS\n",
        "            )\n",
        "\n",
        "            # Train\n",
        "            train_acc, val_acc, epoch_time, gate_count, circuit_depth = self.train_epoch(\n",
        "                qnn, X_train_reduced, X_test_reduced, self.y_train, self.y_test\n",
        "            )\n",
        "\n",
        "            # Update controller\n",
        "            self.controller.update(config_name, val_acc)\n",
        "\n",
        "            # Track\n",
        "            self.training_history['train_acc'].append(train_acc)\n",
        "            self.training_history['val_acc'].append(val_acc)\n",
        "            self.training_history['config'].append(config_name)\n",
        "            self.training_history['epoch_time'].append(epoch_time)\n",
        "            self.training_history['gate_count'].append(gate_count)\n",
        "            self.training_history['circuit_depth'].append(circuit_depth)\n",
        "\n",
        "            # Progress\n",
        "            if config.VERBOSE:\n",
        "                best_config = self.controller.get_best_configuration()\n",
        "                best_reward = np.mean(self.controller.rewards[best_config]) if self.controller.rewards[best_config] else 0\n",
        "\n",
        "                print(f\"Epoch {epoch+1:3d}/{config.N_EPOCHS} | \"\n",
        "                      f\"Config: {config_name:25s} | \"\n",
        "                      f\"Train: {train_acc:.3f} | \"\n",
        "                      f\"Val: {val_acc:.3f} | \"\n",
        "                      f\"Best: {best_config:20s} ({best_reward:.3f}) | \"\n",
        "                      f\"Time: {epoch_time:.1f}s\")\n",
        "\n",
        "        self.total_time = time.time() - self.start_time\n",
        "        self.generate_report()\n",
        "\n",
        "        if config.SAVE_RESULTS:\n",
        "            self.save_results()\n",
        "\n",
        "        if config.PLOT_RESULTS:\n",
        "            self.plot_results()\n",
        "\n",
        "    def generate_report(self):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"NOISY QNN EXPERIMENT REPORT\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "        print(f\"\\nNoise Model:\")\n",
        "        print(f\"  {config.NOISE_PARAMS['description']}\")\n",
        "        print(f\"  Single-qubit: {config.NOISE_PARAMS['single_qubit_error']*100}%\")\n",
        "        print(f\"  Two-qubit: {config.NOISE_PARAMS['two_qubit_error']*100}%\")\n",
        "        print(f\"  Measurement: {config.NOISE_PARAMS['measurement_error']*100}%\")\n",
        "\n",
        "        print(f\"\\nTraining Summary:\")\n",
        "        print(f\"  Total Epochs: {config.N_EPOCHS}\")\n",
        "        print(f\"  Total Time: {self.total_time:.2f}s\")\n",
        "        print(f\"  Avg Time/Epoch: {self.total_time/config.N_EPOCHS:.2f}s\")\n",
        "\n",
        "        best_config = self.controller.get_best_configuration()\n",
        "        best_rewards = self.controller.rewards[best_config]\n",
        "\n",
        "        print(f\"\\nBest Configuration (under noise):\")\n",
        "        print(f\"  Config: {best_config}\")\n",
        "        print(f\"  Mean Reward: {np.mean(best_rewards):.4f}\")\n",
        "        print(f\"  Std Dev: {np.std(best_rewards):.4f}\")\n",
        "        print(f\"  Times Selected: {len(best_rewards)}\")\n",
        "\n",
        "        print(f\"\\nAll Configurations:\")\n",
        "        print(f\"{'Configuration':<25s} {'Mean':<10s} {'Std':<10s} {'Count':<8s}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        stats = self.controller.get_statistics()\n",
        "        for stat in stats:\n",
        "            print(f\"{stat['configuration']:<25s} \"\n",
        "                  f\"{stat['mean_reward']:<10.4f} \"\n",
        "                  f\"{stat['std_reward']:<10.4f} \"\n",
        "                  f\"{stat['count']:<8d}\")\n",
        "\n",
        "        print(f\"\\n{'='*70}\\n\")\n",
        "\n",
        "    def save_results(self):\n",
        "        results = {\n",
        "            'config': {\n",
        "                'n_qubits': config.N_QUBITS,\n",
        "                'n_layers': config.N_LAYERS,\n",
        "                'n_epochs': config.N_EPOCHS,\n",
        "                'noise_params': config.NOISE_PARAMS\n",
        "            },\n",
        "            'training_history': self.training_history,\n",
        "            'controller_stats': self.controller.get_statistics(),\n",
        "            'total_time': self.total_time\n",
        "        }\n",
        "\n",
        "        filename = config.OUTPUT_DIR / f'noisy_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        print(f\"✓ Results saved: {filename}\")\n",
        "\n",
        "    def plot_results(self):\n",
        "        fig = plt.figure(figsize=(18, 12))\n",
        "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "        # Plot 1: Training progress\n",
        "        ax = fig.add_subplot(gs[0, :2])\n",
        "        epochs = range(1, len(self.training_history['train_acc']) + 1)\n",
        "        ax.plot(epochs, self.training_history['train_acc'], label='Train', linewidth=2, alpha=0.7)\n",
        "        ax.plot(epochs, self.training_history['val_acc'], label='Validation', linewidth=2, alpha=0.7)\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel('Accuracy')\n",
        "        ax.set_title('Training Progress with Noise')\n",
        "        ax.legend()\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        # Plot 2: Config frequency\n",
        "        ax = fig.add_subplot(gs[0, 2])\n",
        "        config_counts = {cfg: self.controller.selection_counts[cfg] for cfg in self.configurations}\n",
        "        configs = list(config_counts.keys())\n",
        "        counts = list(config_counts.values())\n",
        "\n",
        "        y_pos = np.arange(len(configs))\n",
        "        ax.barh(y_pos, counts)\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(configs, fontsize=9)\n",
        "        ax.set_xlabel('Times Selected')\n",
        "        ax.set_title('Config Selection')\n",
        "        ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "        # Plot 3: Reward over time\n",
        "        ax = fig.add_subplot(gs[1, :2])\n",
        "        ax.plot(self.controller.reward_history, linewidth=2, color='green', alpha=0.7)\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel('Reward (Val Accuracy)')\n",
        "        ax.set_title('Reward Over Time')\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        # Plot 4: Config timeline\n",
        "        ax = fig.add_subplot(gs[1, 2])\n",
        "        config_to_y = {cfg: i for i, cfg in enumerate(self.configurations)}\n",
        "\n",
        "        for i, (cfg, reward) in enumerate(zip(self.controller.selection_history,\n",
        "                                              self.controller.reward_history)):\n",
        "            ax.scatter(i, config_to_y[cfg], c=[reward], vmin=0, vmax=1,\n",
        "                      cmap='viridis', s=80, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "        ax.set_yticks(range(len(self.configurations)))\n",
        "        ax.set_yticklabels(self.configurations, fontsize=8)\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_title('Config Timeline')\n",
        "\n",
        "        # Plot 5: Performance by config\n",
        "        ax = fig.add_subplot(gs[2, :])\n",
        "        stats = self.controller.get_statistics()\n",
        "        configs = [s['configuration'] for s in stats]\n",
        "        means = [s['mean_reward'] for s in stats]\n",
        "        stds = [s['std_reward'] for s in stats]\n",
        "\n",
        "        x_pos = np.arange(len(configs))\n",
        "        ax.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)\n",
        "        ax.set_xticks(x_pos)\n",
        "        ax.set_xticklabels(configs, rotation=45, ha='right')\n",
        "        ax.set_ylabel('Mean Validation Accuracy')\n",
        "        ax.set_title('Performance by Configuration (with Noise)')\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        plt.suptitle('Noisy 10-Qubit Adaptive QNN Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "        filename = config.OUTPUT_DIR / f'noisy_plots_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        print(f\"✓ Plots saved: {filename}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "print(\"✓ NoisyAdaptiveQNNTrainer defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8avolMiNZRP"
      },
      "source": [
        "## Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cuii8sNkNZRP",
        "outputId": "0a63fadc-5274-4893-a073-6a0792bbeade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset: wine\n",
            "Training: 91, Test: 39\n",
            "\n",
            "======================================================================\n",
            "STARTING NOISY ADAPTIVE QNN TRAINING\n",
            "======================================================================\n",
            "Noise: Realistic NISQ (IBM/Google hardware)\n",
            "Epochs: 30\n",
            "======================================================================\n",
            "\n",
            "  Using default.mixed for 10 qubits with noise\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-426710568.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create and run trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNoisyAdaptiveQNNTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-22478159.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             train_acc, val_acc, epoch_time, gate_count, circuit_depth = self.train_epoch(\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mqnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             )\n",
            "\u001b[0;32m/tmp/ipython-input-22478159.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, qnn, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mbatch_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1151287606.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, X_batch, y_batch, learning_rate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Compute gradients - argnum=0 specifies first argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Update parameters (regular numpy is fine here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/_grad.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mgrad_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/_grad.py\u001b[0m in \u001b[0;36m_grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m             )\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mgrad_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moutgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/core.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvjp_argnums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mvjps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvjpmaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvjp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvjps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mdefvjp_argnums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_argnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0mnew_subscripts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_input_subs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"->\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubs_wrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_subscripts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# using (op0, sublist0, op1, sublist1, ..., sublistout) convention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspecified_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;31m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create and run trainer\n",
        "trainer = NoisyAdaptiveQNNTrainer()\n",
        "trainer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAjdkPVENZRQ"
      },
      "source": [
        "## Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqBfl0O0NZRQ"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    import shutil\n",
        "\n",
        "    shutil.make_archive('noisy_10q_results', 'zip', config.OUTPUT_DIR)\n",
        "\n",
        "    print(\"Downloading results...\")\n",
        "    files.download('noisy_10q_results.zip')\n",
        "    print(\"✓ Download complete!\")\n",
        "else:\n",
        "    print(\"Not on Colab - results saved locally\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}