"""
Phase 2: Quantum Neural Network Implementation
Complete QNN with training, evaluation, and optimization
"""

import pennylane as qml
import numpy as np
from typing import Tuple, List, Optional
import time
from tqdm import tqdm


class QuantumNeuralNetwork:
    """
    Parameterized Quantum Neural Network for binary classification.
    
    Architecture:
    1. Data encoding layer (angle or amplitude)
    2. Parameterized variational layers with entanglement
    3. Measurement layer
    
    Features:
    - Multiple layer support
    - Automatic differentiation
    - Training with Adam optimizer
    - Performance tracking
    """
    
    def __init__(
        self,
        n_qubits: int = 4,
        n_layers: int = 2,
        encoding_type: str = 'angle',
        learning_rate: float = 0.01,
        device_name: str = 'default.qubit'
    ):
        """
        Initialize QNN
        
        Args:
            n_qubits: Number of qubits (matches number of features after selection)
            n_layers: Number of variational layers (keep 2-3 for stability)
            encoding_type: 'angle' or 'amplitude' encoding
            learning_rate: Learning rate for optimizer
            device_name: PennyLane device ('default.qubit', 'lightning.qubit')
        """
        self.n_qubits = n_qubits
        self.n_layers = n_layers
        self.encoding_type = encoding_type
        self.learning_rate = learning_rate
        
        # Create quantum device
        self.dev = qml.device(device_name, wires=n_qubits)
        
        # Initialize parameters
        # Shape: (n_layers, n_qubits, 3) for RX, RY, RZ rotations
        self.weights = self._initialize_weights()
        
        # Training history
        self.history = {
            'train_loss': [],
            'train_accuracy': [],
            'val_loss': [],
            'val_accuracy': []
        }
        
        # Build the quantum circuit
        self.circuit = self._build_circuit()
        
        print(f"âœ“ QNN initialized: {n_qubits} qubits, {n_layers} layers")
        print(f"  Total parameters: {self.weights.size}")
        print(f"  Encoding: {encoding_type}")
    
    def _initialize_weights(self) -> np.ndarray:
        """Initialize weights with small random values"""
        np.random.seed(42)
        # Xavier/Glorot initialization scaled for quantum circuits
        limit = np.sqrt(2.0 / (self.n_qubits + 1))
        weights = np.random.uniform(
            -limit, limit, 
            size=(self.n_layers, self.n_qubits, 3)
        )
        return weights
    
    def _build_circuit(self):
        """Build the parameterized quantum circuit"""
        
        @qml.qnode(self.dev, interface='autograd')
        def circuit(inputs, weights):
            """
            Quantum circuit with encoding and variational layers
            
            Args:
                inputs: Classical data (encoded)
                weights: Trainable parameters
            
            Returns:
                Expectation value in [-1, 1]
            """
            # 1. ENCODING LAYER
            if self.encoding_type == 'angle':
                # Angle encoding: each feature -> RY rotation
                for i in range(min(len(inputs), self.n_qubits)):
                    qml.RY(inputs[i], wires=i)
            
            elif self.encoding_type == 'amplitude':
                # Amplitude encoding: features -> state amplitudes
                # Pad or truncate to 2^n_qubits
                target_dim = 2 ** self.n_qubits
                if len(inputs) < target_dim:
                    padded = np.zeros(target_dim)
                    padded[:len(inputs)] = inputs
                else:
                    padded = inputs[:target_dim]
                
                # Normalize
                norm = np.linalg.norm(padded)
                if norm > 0:
                    padded = padded / norm
                
                qml.AmplitudeEmbedding(
                    features=padded,
                    wires=range(self.n_qubits),
                    normalize=True,
                    pad_with=0.0
                )
            
            # 2. VARIATIONAL LAYERS
            for layer in range(self.n_layers):
                # Parameterized rotations
                for qubit in range(self.n_qubits):
                    qml.RX(weights[layer, qubit, 0], wires=qubit)
                    qml.RY(weights[layer, qubit, 1], wires=qubit)
                    qml.RZ(weights[layer, qubit, 2], wires=qubit)
                
                # Entanglement layer (circular)
                for qubit in range(self.n_qubits - 1):
                    qml.CNOT(wires=[qubit, qubit + 1])
                # Close the circle
                if self.n_qubits > 1:
                    qml.CNOT(wires=[self.n_qubits - 1, 0])
            
            # 3. MEASUREMENT
            # Return expectation value of Pauli-Z on first qubit
            return qml.expval(qml.PauliZ(0))
        
        return circuit
    
    def forward(self, X: np.ndarray) -> np.ndarray:
        """
        Forward pass through the QNN
        
        Args:
            X: Input data, shape (n_samples, n_features)
        
        Returns:
            Predictions, shape (n_samples,)
        """
        predictions = []
        for sample in X:
            pred = self.circuit(sample, self.weights)
            predictions.append(pred)
        return np.array(predictions)
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predict binary classes
        
        Args:
            X: Input data
        
        Returns:
            Binary predictions {0, 1}
        """
        # Get raw predictions in [-1, 1]
        raw_preds = self.forward(X)
        # Convert to binary: >0 -> 1, <=0 -> 0
        return (raw_preds > 0).astype(int)
    
    def _compute_loss(self, X: np.ndarray, y: np.ndarray) -> float:
        """
        Compute binary cross-entropy loss
        
        Args:
            X: Input features
            y: True labels {0, 1}
        
        Returns:
            Loss value
        """
        # Get predictions in [-1, 1]
        predictions = self.forward(X)
        
        # Convert predictions to [0, 1] using sigmoid-like transformation
        # Map [-1, 1] -> [0, 1]
        probs = (predictions + 1) / 2
        
        # Clip to avoid log(0)
        probs = np.clip(probs, 1e-7, 1 - 1e-7)
        
        # Binary cross-entropy
        loss = -np.mean(
            y * np.log(probs) + (1 - y) * np.log(1 - probs)
        )
        
        return float(loss)
    
    def _compute_accuracy(self, X: np.ndarray, y: np.ndarray) -> float:
        """Compute classification accuracy"""
        predictions = self.predict(X)
        return np.mean(predictions == y)
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: Optional[np.ndarray] = None,
        y_val: Optional[np.ndarray] = None,
        epochs: int = 50,
        batch_size: Optional[int] = None,
        verbose: bool = True
    ) -> dict:
        """
        Train the QNN using gradient descent
        
        Args:
            X_train: Training features
            y_train: Training labels {0, 1}
            X_val: Validation features (optional)
            y_val: Validation labels (optional)
            epochs: Number of training epochs
            batch_size: Batch size (None = full batch)
            verbose: Print training progress
        
        Returns:
            Training history dictionary
        """
        # Ensure labels are binary {0, 1}
        y_train = np.array(y_train)
        if y_val is not None:
            y_val = np.array(y_val)
        
        # Set up optimizer (using simple gradient descent for now)
        opt = qml.GradientDescentOptimizer(stepsize=self.learning_rate)
        
        # Define cost function for optimization
        def cost_fn(weights):
            self.weights = weights
            return self._compute_loss(X_train, y_train)
        
        if verbose:
            print(f"\n{'='*60}")
            print(f"TRAINING QNN")
            print(f"{'='*60}")
            print(f"Training samples: {len(X_train)}")
            if X_val is not None:
                print(f"Validation samples: {len(X_val)}")
            print(f"Epochs: {epochs}")
            print(f"Learning rate: {self.learning_rate}")
            print(f"{'='*60}\n")
        
        # Training loop
        start_time = time.time()
        
        iterator = tqdm(range(epochs), desc="Training") if verbose else range(epochs)
        
        for epoch in iterator:
            # Update weights
            self.weights = opt.step(cost_fn, self.weights)
            
            # Compute metrics
            train_loss = self._compute_loss(X_train, y_train)
            train_acc = self._compute_accuracy(X_train, y_train)
            
            self.history['train_loss'].append(train_loss)
            self.history['train_accuracy'].append(train_acc)
            
            # Validation metrics
            if X_val is not None and y_val is not None:
                val_loss = self._compute_loss(X_val, y_val)
                val_acc = self._compute_accuracy(X_val, y_val)
                self.history['val_loss'].append(val_loss)
                self.history['val_accuracy'].append(val_acc)
            
            # Update progress bar
            if verbose and (epoch + 1) % 5 == 0:
                msg = f"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f} - Acc: {train_acc:.4f}"
                if X_val is not None:
                    msg += f" - Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.4f}"
                iterator.set_description(msg)
        
        training_time = time.time() - start_time
        
        if verbose:
            print(f"\n{'='*60}")
            print(f"TRAINING COMPLETE")
            print(f"{'='*60}")
            print(f"Training time: {training_time:.2f}s")
            print(f"Final train accuracy: {self.history['train_accuracy'][-1]:.4f}")
            if X_val is not None:
                print(f"Final val accuracy: {self.history['val_accuracy'][-1]:.4f}")
            print(f"{'='*60}\n")
        
        self.history['training_time'] = training_time
        return self.history
    
    def evaluate(self, X: np.ndarray, y: np.ndarray) -> dict:
        """
        Evaluate the QNN on test data
        
        Args:
            X: Test features
            y: Test labels
        
        Returns:
            Dictionary with metrics
        """
        loss = self._compute_loss(X, y)
        accuracy = self._compute_accuracy(X, y)
        predictions = self.predict(X)
        
        # Compute confusion matrix elements
        true_pos = np.sum((predictions == 1) & (y == 1))
        true_neg = np.sum((predictions == 0) & (y == 0))
        false_pos = np.sum((predictions == 1) & (y == 0))
        false_neg = np.sum((predictions == 0) & (y == 1))
        
        return {
            'loss': loss,
            'accuracy': accuracy,
            'true_positives': int(true_pos),
            'true_negatives': int(true_neg),
            'false_positives': int(false_pos),
            'false_negatives': int(false_neg)
        }
    
    def get_circuit_info(self) -> dict:
        """Get information about the quantum circuit"""
        # Create a dummy input to analyze circuit
        dummy_input = np.ones(self.n_qubits) * 0.5
        
        # Get circuit specifications
        specs = qml.specs(self.circuit)(dummy_input, self.weights)
        
        return {
            'n_qubits': self.n_qubits,
            'n_layers': self.n_layers,
            'n_parameters': self.weights.size,
            'gate_count': specs.get('gate_sizes', {}).get(1, 0) + specs.get('gate_sizes', {}).get(2, 0),
            'circuit_depth': specs.get('depth', 0),
            'encoding_type': self.encoding_type
        }


# ========================================
# TESTING AND VALIDATION
# ========================================

def test_qnn_basic():
    """Test basic QNN functionality"""
    print("\n" + "="*60)
    print("TEST 1: Basic QNN Functionality")
    print("="*60)
    
    # Create simple dataset
    np.random.seed(42)
    X = np.random.rand(20, 4) * np.pi
    y = (np.sum(X, axis=1) > 2 * np.pi).astype(int)
    
    # Split data
    X_train, y_train = X[:15], y[:15]
    X_test, y_test = X[15:], y[15:]
    
    # Create and test QNN
    qnn = QuantumNeuralNetwork(n_qubits=4, n_layers=2)
    
    # Test forward pass
    pred = qnn.forward(X_train[:2])
    print(f"âœ“ Forward pass works: {pred.shape}")
    
    # Test prediction
    pred_classes = qnn.predict(X_train[:2])
    print(f"âœ“ Prediction works: {pred_classes}")
    
    # Test evaluation
    metrics = qnn.evaluate(X_test, y_test)
    print(f"âœ“ Evaluation works: accuracy = {metrics['accuracy']:.4f}")
    
    # Get circuit info
    info = qnn.get_circuit_info()
    print(f"âœ“ Circuit info: {info['gate_count']} gates, depth {info['circuit_depth']}")


def test_qnn_training():
    """Test QNN training on Iris dataset"""
    print("\n" + "="*60)
    print("TEST 2: Training on Real Data (Iris)")
    print("="*60)
    
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    
    # Load data
    iris = load_iris()
    X, y = iris.data, iris.target
    
    # Binary classification (classes 0 and 1)
    mask = y < 2
    X, y = X[mask], y[mask]
    
    # Split and normalize
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    
    # Scale to [0, Ï€] for angle encoding
    X_train = (X_train + 3) * np.pi / 6
    X_test = (X_test + 3) * np.pi / 6
    
    # Create and train QNN
    qnn = QuantumNeuralNetwork(
        n_qubits=4,
        n_layers=2,
        learning_rate=0.05
    )
    
    history = qnn.train(
        X_train, y_train,
        X_test, y_test,
        epochs=30,
        verbose=True
    )
    
    # Final evaluation
    metrics = qnn.evaluate(X_test, y_test)
    print(f"\n{'='*60}")
    print(f"FINAL RESULTS")
    print(f"{'='*60}")
    print(f"Test Accuracy: {metrics['accuracy']:.2%}")
    print(f"Test Loss: {metrics['loss']:.4f}")
    print(f"{'='*60}\n")
    
    return qnn, history


def test_both_encodings():
    """Compare angle vs amplitude encoding"""
    print("\n" + "="*60)
    print("TEST 3: Compare Encoding Methods")
    print("="*60)
    
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    
    # Load and prepare data
    iris = load_iris()
    X, y = iris.data, iris.target
    mask = y < 2
    X, y = X[mask], y[mask]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    X_train = (X_train + 3) * np.pi / 6
    X_test = (X_test + 3) * np.pi / 6
    
    results = {}
    
    for encoding in ['angle', 'amplitude']:
        print(f"\n--- Testing {encoding.upper()} encoding ---")
        
        qnn = QuantumNeuralNetwork(
            n_qubits=4,
            n_layers=2,
            encoding_type=encoding,
            learning_rate=0.05
        )
        
        history = qnn.train(
            X_train, y_train,
            X_test, y_test,
            epochs=20,
            verbose=False
        )
        
        metrics = qnn.evaluate(X_test, y_test)
        results[encoding] = {
            'test_accuracy': metrics['accuracy'],
            'final_train_acc': history['train_accuracy'][-1],
            'training_time': history['training_time']
        }
        
        print(f"Test Accuracy: {metrics['accuracy']:.2%}")
        print(f"Training Time: {history['training_time']:.2f}s")
    
    print(f"\n{'='*60}")
    print(f"ENCODING COMPARISON")
    print(f"{'='*60}")
    for encoding, res in results.items():
        print(f"{encoding.capitalize()}: {res['test_accuracy']:.2%} "
              f"({res['training_time']:.1f}s)")
    print(f"{'='*60}\n")


# ========================================
# MAIN EXECUTION
# ========================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("PHASE 2: QUANTUM NEURAL NETWORK TESTING")
    print("="*60)
    
    # Run all tests
    test_qnn_basic()
    test_qnn_training()
    test_both_encodings()
    
    print("\n" + "="*60)
    print("âœ“ PHASE 2 COMPLETE - QNN fully functional!")
    print("="*60)
    print("\nNext steps:")
    print("1. Review training results above")
    print("2. Experiment with different hyperparameters")
    print("3. Move to Phase 3: adaptive_controller.py")
    print("4. Start building the adaptive system!")